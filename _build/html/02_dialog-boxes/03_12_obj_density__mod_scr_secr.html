
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR) &#8212; Remote Camera Decision Support Tool</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-PJDP7DQ9Q0"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-PJDP7DQ9Q0');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-PJDP7DQ9Q0');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/03_12_obj_density__mod_scr_secr';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spatial mark-resight (SMR) (Chandler &amp; Royle, 2013; Sollmann et al., 2013a, 2013b)" href="03_13_obj_density__mod_smr.html" />
    <link rel="prev" title="Relative abundance indices" href="03_04_obj_rel_abund__mod_rai.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Remote Camera Decision Support Tool - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Remote Camera Decision Support Tool - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Concept Library
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="RCDST_MockUp_FocusGroups_2024-05-24.html">Capture-recapture (CR) / Capture-mark-recapture (CMR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_lib_test.html">Image library</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_01_obj_inventory__mod_inventory.html">Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_02_obj_divers_rich__mod_divers_rich.html">Species diversity &amp; richness</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_03_obj_occupancy__mod_occupancy.html">Occupancy model (MacKenzie et al., 2002)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_04_obj_rel_abund__mod_rai.html">Relative abundance indices</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_13_obj_density__mod_smr.html">Spatial mark-resight (SMR) (Chandler &amp; Royle, 2013; Sollmann et al., 2013a, 2013b)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_14_obj_density__mod_sc.html">Spatial count (SC) model */ Unmarked spatial capture-recapture (Chandler &amp; Royle, 2013)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_15_obj_density__mod_catspim.html">Categorical partial identity model (catSPIM) (Augustine et al., 2019; Sun et al., 2022)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_16_obj_density__mod_2flankspim.html">Spatial partial identity model (2-flank SPIM) (Augustine et al., 2018)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_17_obj_density__mod_rem.html">Random encounter model (REM) (Rowcliffe et al., 2008, 2013)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_18_obj_density__mod_rest.html">Random encounter and staying time (REST) model (Nakashima et al., 2018)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_19_obj_density__mod_tifc.html">Time in front of the camera (TIFC) (Huggard, 2018; Warbington &amp; Boyce, 2020; tested in Becker et al., 2022)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_20_obj_density__mod_ds.html">Distance sampling (DS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_21_obj_density__mod_tte.html">Time-to-event (TTE) model (Moeller et al., 2018)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_22_obj_density__mod_ste.html">Space-to-event (STE) model (Moeller et al., 2018)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_23_obj_density__mod_is.html">Instantaneous sampling (IS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_24_obj_behaviour__mod_behaviour.html">Behaviour</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool/edit/edits/docs/02_dialog-boxes/03_12_obj_density__mod_scr_secr.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool/issues/new?title=Issue%20on%20page%20%2F02_dialog-boxes/03_12_obj_density__mod_scr_secr.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/02_dialog-boxes/03_12_obj_density__mod_scr_secr.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i-mod-scr-secr">Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="spatial-capture-recapture-scr-spatially-explicit-capture-recapture-secr">
<h1>Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)<a class="headerlink" href="#spatial-capture-recapture-scr-spatially-explicit-capture-recapture-secr" title="Link to this heading">#</a></h1>
<div class="full-width docutils">
<div class="dropdown admonition">
<p class="admonition-title">Click here for more information</p>
<p>later</p>
</div>
</div>
<section id="i-mod-scr-secr">
<span id="id1"></span><h2>Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)<a class="headerlink" href="#i-mod-scr-secr" title="Link to this heading">#</a></h2>
<p><strong>Spatially explicit capture-recapture (SECR) */ Spatial capture-recapture (SCR) (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009):</strong> </p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text"><strong>Assumptions, Pros, Cons</strong></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<strong>Assumptions</strong></div>
<ul class="simple">
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) </p></li>
<li><p class="sd-card-text">Detection probability of different individuals is equal </p>
<ul>
<li><p class="sd-card-text">or, for SECR, individuals have equal detection probability at a given distance from the centre of their home range </p></li>
</ul>
</li>
<li><p class="sd-card-text">Detections of different individuals are independent </p></li>
<li><p class="sd-card-text">Behaviour is unaffected by cameras and marking </p></li>
<li><p class="sd-card-text">Individuals do not lose marks </p></li>
<li><p class="sd-card-text">Individuals are not misidentified </p></li>
<li><p class="sd-card-text">Surveys are independent </p></li>
<li><p class="sd-card-text">For conventional models, geographic closure (i.e., no immigration or emigration) </p></li>
<li><p class="sd-card-text">Spatially explicit models have further assumptions about animal movement ; these include:</p>
<ul>
<li><p class="sd-card-text">Home ranges are stable </p></li>
<li><p class="sd-card-text">Movement is unaffected by cameras </p></li>
<li><p class="sd-card-text">Camera locations are randomly placed with respect to the distribution and orientation of home ranges 
Distribution of home range centres follows a defined distribution (Poisson, or other, e.g., negative binomial) </p></li>
</ul>
</li>
<li><p class="sd-card-text">Demographic closure (i.e., no births or deaths) </p></li>
<li><p class="sd-card-text">Detection probability of different individuals is equal </p>
<ul>
<li><p class="sd-card-text">or, for SECR, individuals have equal detection probability at a given distance from the centre of their home range </p></li>
</ul>
</li>
<li><p class="sd-card-text">Detections of different individuals are independent </p></li>
<li><p class="sd-card-text">Behaviour is unaffected by cameras and marking </p></li>
<li><p class="sd-card-text">Individuals do not lose marks </p></li>
<li><p class="sd-card-text">Individuals are not misidentified </p></li>
<li><p class="sd-card-text">Surveys are independent </p></li>
<li><p class="sd-card-text">For conventional models, geographic closure (i.e., no immigration or emigration) </p></li>
<li><p class="sd-card-text">Spatially explicit models have further assumptions about animal movement ; these include:</p>
<ul>
<li><p class="sd-card-text">Home ranges are stable </p></li>
<li><p class="sd-card-text">Movement is unaffected by cameras </p></li>
<li><p class="sd-card-text">Camera locations are randomly placed with respect to the distribution and orientation of home ranges 
Distribution of home range centres follows a defined distribution (Poisson, or other, e.g., negative binomial) </p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<strong>Pros</strong></div>
<ul class="simple">
<li><p class="sd-card-text">Produces direct estimates of density or population size for explicit spatial regions </p></li>
<li><p class="sd-card-text">Allows researchers to mark a subset of the population/to take advantage of natural markings </p></li>
<li><p class="sd-card-text">Estimates are fully comparable across space, time, species and studies </p></li>
<li><p class="sd-card-text">Density estimates obtained in a single model, fully incorporate spatial information of locations and individuals </p></li>
<li><p class="sd-card-text">Both likelihood-based and Bayesian versions of the model have been implemented in relatively easy-to-use software (DENSITY and SPACECAP, respectively, as well as associated R packages) </p></li>
<li><p class="sd-card-text">Flexibility in study design (e.g., “holes” in the trapping grid) </p></li>
<li><p class="sd-card-text">“Open” SECR  models exist that allow for estimation of recruitment and survival rates </p></li>
<li><p class="sd-card-text">“Avoid ad-hoc definitions of study area and edge effects” </p></li>
<li><p class="sd-card-text">SECR  accounts for variation in individual detection probability; can produce spatial variation in density; SECR  more sensitive “to detect moderate-to-major populations changes” (+/-20-80%) </p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<strong>Cons</strong></div>
<ul class="simple">
<li><p class="sd-card-text">Requires that individuals are identifiable </p></li>
<li><p class="sd-card-text">Requires that a minimum number of individuals are trapped (each recaptured multiple times ideally) </p></li>
<li><p class="sd-card-text">Requires that each individual is captured at a number of camera locations </p></li>
<li><p class="sd-card-text">Multiple cameras per station may be required to identify individuals; difficult to implement at large spatial scales as it requires a high density of cameras </p></li>
<li><p class="sd-card-text">May not be precise enough for long-term monitoring </p></li>
<li><p class="sd-card-text">Cameras must be close enough that animals are detected at multiple camera locations  (may be challenging to implement at large scales as many cameras are needed)” </p></li>
<li><p class="sd-card-text">½ MMDM (Mean Maximum Distance Moved) will usually lead to an underestimation of home range size and thus overestimation of density </p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</details><div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Overview</label><div class="sd-tab-content docutils">
<br>
Spatial capture-recapture (SCR) models are used to estimate animal density. They use a combination of information 
<p>SCR models rely on data in which individual animals are observed on multiple occasions, either being captured, marked and released, or individuals being identified on multiple occasions via specific diagnostic features (e.g., leopard print patterns, dolphin fin markings, etc.).</p>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
Advanced</label><div class="sd-tab-content docutils">
<br>
Spatial capture-recapture (SCR) models can be applied to any survey method where animals are individually identifiable and trap locations are known: live trapping and tagging, DNA sampling, camera trapping, etc. (Royle et al. 2014). Here, we will discuss camera trap SCR. 
SCR models break populations down into the activity, or home range, centres of individual animals. Let us first imagine we know the number and location of all individuals’ activity centres in a population. If we did, we could easily estimate density/: 
<br>
<br>
<center>
<a class="reference internal image-reference" href="../_images/clarke-et-al_2023_eqn_scr1.png"><img alt="../_images/clarke-et-al_2023_eqn_scr1.png" src="../_images/clarke-et-al_2023_eqn_scr1.png" style="width: 300px;" /></a>
</center>
<p>``
assuming each member of the population has an activity centre, and so the number of activity centres is equivalent to population size; and since the area encompassing all activity centres is the total area sampled by the camera array (i.e., the sampling frame; Sollmann 2018). In reality, we do not know the number and location of activity centres – indeed, the estimated number and location of activity centres is the SCR model output.</p>
<p>To resolve the number and location of activity centres – and thus estimate density – SCR models combine information about 1) where animals are detected in space (using an observation model) and 2) how animals are distributed in space (using a spatial process moel; Figur 4; Royle 2/</p>
<p>6<r>
)```{image} ../03_images/03_image_files/clarke-et-al_2023_fig4_clipped.png
:width: 80px
:align: center
``</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
The observation model uses the record of where each individual was detected (i.e., individuals’ detection histories) to infer the location of each individual’s respective activity centre (Figure 5A; Chandler and Royle 2013, Royle 2016). It relies on the inverse relationship between detection probability and cameratrap-to-activity-centre distance: as the distance between a camera and an individual’s activity centre increases, the likelihood that individual will be detected there decreases (Figure 5B; Royle et al. 2014). So, animals will be detected most frequently at camera traps near their activity centres, and least frequently (or not at all) at camera traps far from their activity centres. Because the locations of activity centres are unknown, we use a spatial process model to approximate their distribution. Point-process models are a common choice (Royle 2016). A point-process model is a random pattern of points in space (Baddeley, no date); it can be homogenous (completely spatially random) or inhomogeneous (the density of points depends on landscape/habitat covariates; Royle 2016).

Taken together: SCR essentially “downscales” density – a population-level estimator – to the level of the individual. The model asks: where does each animal live (Royle 2016)? Although the location of animals’ activity centres is not known, we can use information about where individuals are captured (detection histories) and how activity centres are distributed in space (point-process model) to infer where they live, and thus estimate density (Royle 2016). SCR can be implemented using many statistical frameworks, including full likelihood estimation (Borchers and Efford 2008), dataaugmented maximum likelihood estimation (Royle et al. 2014), and data-augmented Bayesian estimation (Royle and Young 2008; Morin et al. 2022). 

When deploying cameras for SCR analysis, practitioners must balance the area covered by the camera array with trap spacing to maximize both the number of unique individuals captured and the number of spatial recaptures of each individual. A larger sampling area will yield a higher count of unique individuals; closely-spaced traps will yield a higher number of spatial recaptures (i.e., detections of the same individual at different camera traps; Royle et al. 2014). Both are important for SCR density estimation. Cameras should also be deployed across habitat types with different levels of use (Morin et al. 2022, Sun et al. 2014). Grid and clustered sampling designs can help meet all these needs (Clark 2019, Sun et al. 2014). Note that optimal camera trap placement and spacing will change with focal species, landscape and project limitations. 
See Clark (2019), Dupont et al. (2021), Fleming et al. (2021), McFarlane et al. (2020), Nawaz et al. (2021), Romairone et al. 2018, Sollmann et al. (2012) and Sun et al.  (2014) for more detailed explorations of SCR study de```{image} ./03_images/03_image_files/clarke-et-al_2023_fig5_clipped.png
:alt: clarke-et-al_2023_fig5
:width: 80px
:align: center
</pre></div>
</div>
<p>nter</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
&lt;fo size=&quot;8&quot;&gt;
&gt; **{{ ref_intext_clarke-et-al_2023 }} - Figure 5.** Adapted from Morin et al. (2022) and Royle et al. (2014). A) A diagram of how the individual activity centres (circles) that make up a population might overlap with a camera array (grey crosses). The red circle highlights an example individual’s activity centre. The red arrows point towards camera stations where the red individual was detected; the numbers beside the camera stations show how many times the red individual was detected at each station. Note, the number and location of individual’s activity centres is not known, but rather inferred from the spatial pattern of detections (i.e., the number of detections of each individual at camera stations of known location). B) An example graph showing how the probability the red individual is detected at a camera station decreases with distance from its activity centre. This is reflected in A); as the distance between the red individual’s activity centre and a camera station increases, the number of detections dwindles. σ is the spatial scale parameter; it describes how detection probability decreases with increasing distance.
&lt;/font&gt;

Another aspect of sampling design practitioners must consider is the number and configuration of cameras deployed at a station to identify animals to the individual. Left and right flanks may need to be photographed simultaneously, for example, to avoid assigning different identities to each side (Augustine et al., 2018); as another example, chest markings may need to be photographed from multiple angles at bait stations to be able to resolve identity (Proctor et al., 2022).
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Visual Resources</label><div class="sd-tab-content docutils">
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<a class="reference internal image-reference" href="02_dialog-boxes/03_images/image_files/mccomb-et-al_2010_fig10.1.png"><img alt="02_dialog-boxes/03_images/image_files/mccomb-et-al_2010_fig10.1.png" class="align-center" src="02_dialog-boxes/03_images/image_files/mccomb-et-al_2010_fig10.1.png" style="width: 80px;" /></a>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<a class="reference internal image-reference" href="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig4_clipped.png"><img alt="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig4_clipped.png" class="align-center" src="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig4_clipped.png" style="width: 80px;" /></a>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<a class="reference internal image-reference" href="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig5_clipped.png"><img alt="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig5_clipped.png" class="align-center" src="02_dialog-boxes/03_images/image_files/clarke-et-al_2023_fig5_clipped.png" style="width: 80px;" /></a>
</div>
</div>
</div>
</div>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-3 sd-row-cols-xs-3 sd-row-cols-sm-3 sd-row-cols-md-3 sd-row-cols-lg-3 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
</div>
</div>
</div>
</div>
</div>
</div>
<input id="sd-tab-item-3" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-3">
Analytical tools &amp; resources</label><div class="sd-tab-content docutils">
<p>+—————-+—————————————————————————–+——————-+——————————————————————————————————————————————–+———————————————-+
| <strong>Type</strong>       | <strong>Name</strong>                                                                    | <strong>Note</strong>          | <strong>URL</strong>                                                                                                                                    | <strong>Reference</strong>                                |
+—————-+—————————————————————————–+——————-+——————————————————————————————————————————————–+———————————————-+</p>
<div class="sd-tab-item docutils">
<p class="sd-tab-label rubric">References</p>
<div class="sd-tab-content docutils">
<font size="1">
{{ ref_textbib_clarke-et-al_2023 }}
{{ ref_textbib_efford_2024 }}
{{ ref_textbib_gopalaswamy-et-al_2021 }}
{{ ref_textbib_ref_efford-boulanger_2019  }}
</font>
</div>
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-4">
Glossary</label><div class="sd-tab-content docutils">
<dl class="simple myst">
<dt><strong>*Access Method</strong></dt><dd><p>The method used to reach the camera location (e.g., on “Foot,” “ATV,” “Helicopter,” etc.).
….</p>
</dd>
</dl>
</p>
<p>``</p>
</div>
</div>
<p>Spatial capture-recapture (SCR) models can be applied to any survey method where animals are individually identifiable and trap locations are known: live trapping and tagging, DNA sampling, camera trapping, etc. (Royle et al. 2014). Here, we will discuss camera trap SCR.
SCR models break populations down into the activity, or home range, centres of individual animals. Let us first imagine we know the number and location of all individuals’ activity centres in a population. If we did, we could easily estimate density:</p>
<a class="reference internal image-reference" href="../_images/clarke-et-al_2023_eqn_scr1.png"><img alt="../_images/clarke-et-al_2023_eqn_scr1.png" class="align-center" src="../_images/clarke-et-al_2023_eqn_scr1.png" style="width: 80px;" /></a>
<p>assuming each member of the population has an activity centre, and so the number of activity centres is equivalent to population size; and since the area encompassing all activity centres is the total area sampled by the camera array (i.e., the sampling frame; Sollmann 2018). In reality, we do not know the number and location of activity centres – indeed, the estimated number and location of activity centres is the SCR model output.</p>
<p>To resolve the number and location of activity centres – and thus estimate density – SCR models combine information about 1) where animals are detected in space (using an observation model) and 2) how animals are distributed in space (using a spatial process model; Figure 4; Royle 201figure</p>
<a class="reference internal image-reference" href="../_images/clarke-et-al_2023_fig4_clipped.png"><img alt="../_images/clarke-et-al_2023_fig4_clipped.png" class="align-center" src="../_images/clarke-et-al_2023_fig4_clipped.png" style="width: 80px;" /></a>
<p>The observation model uses the record of where each individual was detected (i.e., individuals’ detection histories) to infer the location of each individual’s respective activity centre (Figure 5A; Chandler and Royle 2013, Royle 2016). It relies on the inverse relationship between detection probability and cameratrap-to-activity-centre distance: as the distance between a camera and an individual’s activity centre increases, the likelihood that individual will be detected there decreases (Figure 5B; Royle et al. 2014). So, animals will be detected most frequently at camera traps near their activity centres, and least frequently (or not at all) at camera traps far from their activity centres. Because the locations of activity centres are unknown, we use a spatial process model to approximate their distribution. Point-process models are a common choice (Royle 2016). A point-process model is a random pattern of points in space (Baddeley, no date); it can be homogenous (completely spatially random) or inhomogeneous (the density of points depends on landscape/habitat covariates; Royle 2016).</p>
<p>Taken together: SCR essentially “downscales” density – a population-level estimator – to the level of the individual. The model asks: where does each animal live (Royle 2016)? Although the location of animals’ activity centres is not known, we can use information about where individuals are captured (detection histories) and how activity centres are distributed in space (point-process model) to infer where they live, and thus estimate density (Royle 2016). SCR can be implemented using many statistical frameworks, including full likelihood estimation (Borchers and Efford 2008), dataaugmented maximum likelihood estimation (Royle et al. 2014), and data-augmented Bayesian estimation (Royle and Young 2008; Morin et al. 2022).</p>
<p>When deploying cameras for SCR analysis, practitioners must balance the area covered by the camera array with trap spacing to maximize both the number of unique individuals captured and the number of spatial recaptures of each individual. A larger sampling area will yield a higher count of unique individuals; closely-spaced traps will yield a higher number of spatial recaptures (i.e., detections of the same individual at different camera traps; Royle et al. 2014). Both are important for SCR density estimation. Cameras should also be deployed across habitat types with different levels of use (Morin et al. 2022, Sun et al. 2014). Grid and clustered sampling designs can help meet all these needs (Clark 2019, Sun et al. 2014). Note that optimal camera trap placement and spacing will change with focal species, landscape and project limitations.
See Clark (2019), Dupont et al. (2021), Fleming et al. (2021), McFarlane et al. (2020), Nawaz et al. (2021), Romairone et al. 2018, Sollmann et al. (2012) and Sun et al.  (2014) for more detailed explorations of SCfiguredy design.</p>
<img alt="03_images/03_image_files/clarke-et-t:clarke-et-al_2023_fig5" src="03_images/03_image_files/clarke-et-t:clarke-et-al_2023_fig5" />
<font size="8">
> **{{ ref_intext_clarke-et-al_2023 }} - Figure 5.** Adapted from Morin et al. (2022) and Royle et al. (2014). A) A diagram of how the individual activity centres (circles) that make up a population might overlap with a camera array (grey crosses). The red circle highlights an example individual’s activity centre. The red arrows point towards camera stations where the red individual was detected; the numbers beside the camera stations show how many times the red individual was detected at each station. Note, the number and location of individual’s activity centres is not known, but rather inferred from the spatial pattern of detections (i.e., the number of detections of each individual at camera stations of known location). B) An example graph showing how the probability the red individual is detected at a camera station decreases with distance from its activity centre. This is reflected in A); as the distance between the red individual’s activity centre and a camera station increases, the number of detections dwindles. σ is the spatial scale parameter; it describes how detection probability decrth increasing distance.
</font>
<p>Another aspect of sampling design practitioners must consider is the number and configuration of cameras deployed at a station to identify animals to the individual. Left and right flanks may need to be photographed simultaneously, for example, to avoid assigning different identities to each side (Augustine et al., 2018); as another example, chest markings may need to be photographed from multiple angles at bait stations to be able to resolve identity (Proctor et al., 2022).</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03_04_obj_rel_abund__mod_rai.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Relative abundance indices</p>
      </div>
    </a>
    <a class="right-next"
       href="03_13_obj_density__mod_smr.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Spatial mark-resight (SMR) (Chandler &amp; Royle, 2013; Sollmann et al., 2013a, 2013b)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i-mod-scr-secr">Spatial capture-recapture (SCR) */ Spatially explicit capture recapture (SECR)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>