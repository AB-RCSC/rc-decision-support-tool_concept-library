
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Glossary &#8212; Remote Camera Decision Support Tool - Concept Library</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-PJDP7DQ9Q0"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-PJDP7DQ9Q0');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-PJDP7DQ9Q0');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_dialog-boxes/09_gloss_ref/09_glossary';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Occupancy" href="../03_03_mod_occupancy.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Remote Camera Decision Support Tool - Concept Library - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Remote Camera Decision Support Tool - Concept Library - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Testing 123</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_template_master_test.html">test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_00_welcome.html">Welcome to the Remote Camera Decision Support Tool!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Objectives &amp; Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_02_objective.html">State Variable <em>vs.</em> Objective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_03_num_cams.html">Number of cameras available</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Study area &amp; Site selection constraints</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_06_cam_strat_covar.html">Stratified by covariates</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Duration &amp; Timing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_08_surv_dur_min_max.html">Duration (minimum &amp; maximum)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_10_sp_asymptote.html">Species-accumulation asymptote</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Target species</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_13_sp_info.html">Ecological knowledge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_14_sp_type.html">Carnivore / ungulate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_16_sp_occ_restr.html">Occurrence restricted</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_17_sp_hr_size.html">Home range size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_18_sp_size.html">Body size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_19_sp_rarity.html">Rarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_20_sp_detprob_cat.html">Detection probability</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data &amp; Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_47_cam_independent.html">Camera location independence</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Recommendations - Modelling Approaches</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../03_01_mod_inventory.html">Species inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_02_mod_divers_rich.html">Species diversity &amp; richness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_03_mod_occupancy.html">Occupancy</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Glossary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool_concept-library" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool_concept-library/edit/main/02_dialog-boxes/09_gloss_ref/09_glossary.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AB-RCSC/rc-decision-support-tool_concept-library/issues/new?title=Issue%20on%20page%20%2F02_dialog-boxes/09_gloss_ref/09_glossary.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/02_dialog-boxes/09_gloss_ref/09_glossary.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Glossary</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>{#glossary}</p>
<section class="tex2jax_ignore mathjax_ignore" id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h1>
<p>{.glossary}</p>
<p id="test">test</p>
<p>{#access_method}</p>
<dl class="simple myst">
<dt><strong>*Access Method</strong></dt><dd><p>The method used to reach the camera location (e.g., on “Foot,” “ATV,” “Helicopter,” etc.).</p>
</dd>
</dl>
<p>{#age_class_adult}</p>
<dl class="simple myst">
<dt><strong>Adult</strong></dt><dd><p>Animals that are old enough to breed; reproductively mature.</p>
</dd>
</dl>
<p>{#age_class}</p>
<dl class="simple myst">
<dt><strong>Age Class</strong></dt><dd><p>The age classification of individual(s) being categorized (e.g., “Adult,” “Juvenile,” “Subadult,” “Subadult - Young of Year,” “Subadult - Yearling”, or “Unknown”).</p>
</dd>
</dl>
<p>{#analyst}</p>
<dl class="simple myst">
<dt><strong>Analyst</strong></dt><dd><p>The first and last names of the individual who provided the observation data point (species identification and associated information). If there are multiple analysts for an observation, enter the primary analyst.</p>
</dd>
</dl>
<p>{#animal_id}</p>
<dl class="simple myst">
<dt><strong>*Animal ID</strong></dt><dd><p>A unique ID for an animal that can be uniquely identified (e.g., marked in some way). If multiple unique individuals are identified, enter an Animal ID for each as a unique row. Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#baitlure_audible_lure}</p>
<dl class="simple myst">
<dt>Audible lure</dt><dd><p>Sounds imitating noises of prey or conspecifics that draw animals closer by eliciting curiosity (Schlexer, 2008).</p>
</dd>
</dl>
<p>{#baitlure_bait}</p>
<dl class="simple myst">
<dt>Bait</dt><dd><p>A food item (or other substance) that is placed to attract animals via the sense of taste and olfactory cues (Schlexer, 2008).</p>
</dd>
</dl>
<p>{#baitlure_bait_lure_type}</p>
<dl class="simple myst">
<dt><strong>Bait/Lure Type</strong></dt><dd><p>The type of bait or lure used at a camera location. Record “None” if a Bait/Lure Type was not used and “Unknown” if not known. If “Other,” describe in the Deployment Comments.</p>
</dd>
</dl>
<p>{#batteries_replaced}</p>
<dl class="simple myst">
<dt><strong>*Batteries Replaced</strong></dt><dd><p>Whether the camera’s batteries were replaced.</p>
</dd>
</dl>
<p>{#behaviour}</p>
<dl class="simple myst">
<dt><strong>*Behaviour</strong></dt><dd><p>The behaviour of the individual(s) being categorized (e.g., “Standing,” “Drinking,” “Vigilant,” etc.).</p>
</dd>
</dl>
<p>{#camera_active_on_arrival}</p>
<dl class="simple myst">
<dt><strong>*Camera Active On Arrival</strong></dt><dd><p>Whether a camera was functional upon arrival.</p>
</dd>
</dl>
<p>{#camera_active_on_departure}</p>
<dl class="simple myst">
<dt><strong>*Camera Active On Departure</strong></dt><dd><p>Whether a camera was functional upon departure.</p>
</dd>
</dl>
<p>{#camera_angle}</p>
<dl class="simple myst">
<dt>Camera angle</dt><dd><p>The degree at which the camera is pointed toward the FOV Target Feature relative to the horizontal ground surface (with respect to slope, if applicable).</p>
</dd>
</dl>
<p>{#camera_attachment}</p>
<dl class="simple myst">
<dt><strong>*Camera Attachment</strong></dt><dd><p>The method/tools used to attach the camera (e.g., attached to a tree with a bungee cord; reported as codes such as “Tree + Bungee/Strap”). If “Other,” describe in the Camera Location Comments.</p>
</dd>
</dl>
<p>{#camera_damaged}</p>
<dl class="simple myst">
<dt><strong>*Camera Damaged</strong></dt><dd><p>Whether the camera was damaged or malfunctioning; if there is any damage to the device (physical or mechanical), the crew should describe the damage in the Service/Retrieval Comments.</p>
</dd>
</dl>
<p>{#camera_days_per_camera_location}</p>
<dl class="simple myst">
<dt>Camera days per camera location</dt><dd><p>The number of days each camera was active and functioning during the period it was deployed (e.g., 24-hour periods or the difference in days between the Deployment Start Date Time and the Deployment End Date Time if there were no interruptions).</p>
</dd>
</dl>
<p>{#camera_direction}</p>
<dl class="simple myst">
<dt><strong>*Camera Direction (degrees)</strong></dt><dd><p>The cardinal direction that a camera faces. Ideally, cameras should face north (N; i.e. “0” degrees), or south (S; i.e. “180” degrees) if north is not possible. The Camera Direction should be chosen to ensure the field of view (FOV) is of the original FOV target feature.</p>
</dd>
</dl>
<p>{#camera_height}</p>
<dl class="simple myst">
<dt><strong>Camera Height (m)</strong></dt><dd><p>The height from the ground (below snow) to the bottom of the lens (metres; to the nearest 0.05 m).</p>
</dd>
</dl>
<p>{#camera_id}</p>
<dl class="simple myst">
<dt><strong>Camera ID</strong></dt><dd><p>A unique alphanumeric ID for the camera that distinguishes it from other cameras of the same make or model.</p>
</dd>
</dl>
<p>{#camera_location}</p>
<dl class="simple myst">
<dt>Camera location</dt><dd><p>The location where a single camera was placed (recorded as “Camera Location Name”).</p>
</dd>
</dl>
<p>{#camera_location_characteristics}</p>
<dl class="simple myst">
<dt><strong>*Camera Location Characteristic(s)</strong></dt><dd><p>Any significant features around the camera at the time of the visit. This may include for example, manmade or natural linear features (e.g., trails), habitat types (e.g., wetlands), wildlife structure (e.g., beaver dam). If “Other,” describe in the Camera Location Comments.</p>
</dd>
<dd><p>Camera Location Characteristics differ from FOV Target Features in that Camera Location Characteristics could include those not in the camera’s Field of View. If “Other,” describe in the Camera Location Comments.</p>
</dd>
</dl>
<p>{#camera_location_comments}</p>
<dl class="simple myst">
<dt><strong>*Camera Location Comments</strong></dt><dd><p>Comments describing additional details about a camera location.</p>
</dd>
</dl>
<p>{#camera_location_name}</p>
<dl class="simple myst">
<dt><strong>Camera Location Name</strong></dt><dd><p>A unique alphanumeric identifier for the location where a single camera was placed (e.g., “bh1,” “bh2”).</p>
</dd>
</dl>
<p>{#camera_make}</p>
<dl class="simple myst">
<dt><strong>Camera Make</strong></dt><dd><p>The make of a particular camera (i.e., the manufacturer, e.g., “Reconyx” or “Bushnell”).</p>
</dd>
</dl>
<p>{#camera_model}</p>
<dl class="simple myst">
<dt><strong>Camera Model</strong></dt><dd><p>The model number or name of a particular camera (e.g., “PC900” or “Trophy Cam HD”).</p>
</dd>
</dl>
<p>{#camera_serial_number}</p>
<dl class="simple myst">
<dt><strong>Camera Serial Number</strong></dt><dd><p>The serial number of a particular camera, which is usually found inside the camera cover (e.g., “P900FF04152022”).</p>
</dd>
</dl>
<p>{#camera_spacing}</p>
<dl class="simple myst">
<dt>Camera spacing</dt><dd><p>The distance between cameras (i.e., also referred to as “inter-trap distance”). This will be influenced by the chosen sampling design, the Survey Objectives, the Target Species and data analysis.</p>
</dd>
</dl>
<p>{#mods_cr_cmr}</p>
<dl class="simple myst">
<dt>Capture-recapture (CR) model / Capture-mark-recapture (CMR) model (Karanth, 1995; Karanth &amp; Nichols, 1998)</dt><dd><p>A method of estimating the abundance or density of marked populations using the number of animals detected and the likelihood animals will be detected (detection probability). CR (Karanth, 1995; Karanth &amp; Nichols, 1998) can be used to estimate vital rates where all newly detected unmarked animals become marked and are distinguishable in future (Efford, 2022). Spatially explicit capture-recapture (SECR; Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008) models have largely replaced CR and CMR models and provide more accurate density estimates (Blanc et al., 2013, Obbard et al., 2010, Sollmann et al., 2011).</p>
</dd>
</dl>
<p>{#mods_catspim}</p>
<dl class="simple myst">
<dt>Categorical partial identity model (catSPIM) (Augustine et al., 2019; Sun et al., 2022)</dt><dd><p>A method used to estimate the density of partially marked populations in which the “spatial locations of where partial identity samples are captured to probabilistically resolve their complete identities” (Augustine et al., 2018, 2019). catSPIM models use partial identity traits (e.g., sex class, antler points) to help infer individual identities (Augustine et al., 2019; Sun et al., 2022). catSPIM is an extension of the SC model (Chandler &amp; Royle, 2013).</p>
</dd>
</dl>
<p>{#sampledesign_clustered}</p>
<dl class="simple myst">
<dt>Clustered design</dt><dd><p>Multiple cameras are deployed at a sample station (Figure 3d). A clustered design can be used within a systematic or stratified approach (i.e., systematic clustered design or as a clustered random design [Wearn &amp; Glover-Kapfer, 2017]).</p>
</dd>
</dl>
<p>{#sampledesign_convenience}</p>
<dl class="simple myst">
<dt>Convenience design</dt><dd><p>Camera locations or sample stations are chosen based on logistic considerations (e.g., remoteness, access constraints, and/or costs).</p>
</dd>
</dl>
<p>{#crew}</p>
<dl class="simple myst">
<dt>Crew</dt><dd><p>The first and last names of all the individuals who collected data during the deployment visit (“Deployment Crew”) and service/retrieval visit (“Service/Retrieval Crew”).</p>
</dd>
</dl>
<p>{#cumulative_det_probability}</p>
<dl class="simple myst">
<dt>Cumulative detection probability</dt><dd><p>The probability of detecting a species at least once during the entire survey (Steenweg et al., 2019).</p>
</dd>
</dl>
<p>{#density}</p>
<dl class="simple myst">
<dt>Density</dt><dd><p>The number of individuals per unit area.</p>
</dd>
</dl>
<p>{#deployment}</p>
<dl class="simple myst">
<dt>Deployment</dt><dd><p>A unique placement of a camera in space and time (recorded as “Deployment Name”). There may be multiple deployments for one camera location. Deployments are often considered as the time between visits (i.e., deployment to service, service to service, and service to retrieval). Any change to camera location, sampling period, camera equipment (e.g., Trigger Sensitivity setting, becomes non-functioning), and/or conditions (e.g., not baited then baited later; camera SD card replaced) should be documented as a unique deployment.</p>
</dd>
</dl>
<p>{#deployment_area_photo_numbers}</p>
<dl class="simple myst">
<dt><strong>*Deployment Area Photo Numbers</strong></dt><dd><p>The image numbers for the deployment area photos (if collected, e.g., “DSC100”). These are optionally documented on a Camera Deployment Field Datasheet for each set of camera deployment area photos. Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#deployment_area_photos}</p>
<dl class="simple myst">
<dt>Deployment area photos</dt><dd><p>Photos of the area around the camera location, collected as a permanent, visual record of the FOV Target Features, Camera Location Characteristics, environmental conditions (e.g., vegetation, ecosite, weather) or other variables of interest. The recommendation includes collecting four photos taken from the centre of the target detection zone (Figure 5), facing each of the four cardinal directions. The documentation of the collection of these photos is recorded as “Deployment Area Photos Taken” (Y/N).</p>
</dd>
</dl>
<p>{#deployment_area_photos_taken}</p>
<dl class="simple myst">
<dt><strong>*Deployment Area Photos Taken</strong></dt><dd><p>Whether deployment area photos were taken (yes/no; optional). The recommendation includes collecting four photos taken from the centre of the target detection zone (Figure 5), facing each of the four cardinal directions.</p>
</dd>
</dl>
<p>{#deployment_comments}</p>
<dl class="simple myst">
<dt><strong>*Deployment Comments</strong></dt><dd><p>Comments describing additional details about the deployment.</p>
</dd>
</dl>
<p>{#deployment_crew}</p>
<dl class="simple myst">
<dt><strong>Deployment Crew</strong></dt><dd><p>The first and last names of the individuals who collected data during the deployment visit.</p>
</dd>
</dl>
<p>{#deployment_end_date_time}</p>
<dl class="simple myst">
<dt><strong>Deployment End Date Time (DD-MMM-YYYY HH:MM:SS)</strong></dt><dd><p>The date and time that the data was retrieved for a specific deployment (e.g., 27-Jan-2019 23:00:00). The Deployment End Date Time may not coincide with when the last image or video was collected (i.e., the Image Set End Date Time). Recording this field allows users to account for deployments where no images were captured and to confirm the last date and time that the camera was active.</p>
</dd>
</dl>
<p>{#deployment_image_count}</p>
<dl class="simple myst">
<dt><strong>*Deployment Image Count</strong></dt><dd><p>The total number of images collected during the deployment, including false triggers (i.e., empty images with no wildlife or human present species) and those triggered by a time-lapse setting (if applicable).</p>
</dd>
</dl>
<p>{#deployment_metadata}</p>
<dl class="simple myst">
<dt>Deployment metadata</dt><dd><p>Metadata that is collected each time a camera is deployed. Each deployment event should have its own Camera Deployment Field Datasheet. The relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved.\</p>
</dd>
<dd><p>Refer to Appendix A - Table A5 and Camera Deployment Field Datasheet.</p>
</dd>
</dl>
<p>{#deployment_name}</p>
<dl class="simple myst">
<dt><strong>Deployment Name</strong></dt><dd><p>A unique alphanumeric identifier for a unique camera deployed during a specific survey period (ideally recorded as “Camera Location Name,”_”,Deployment Start Date” (or …*“Deployment End Date”) (e.g., “bh1_17-Jul-2018” or “bh1_17-Jul-2018_21-Jan-2019”).</p>
</dd>
<dd><p>Alternative naming conventions may be used, but the goal should be to minimize duplicate Image Names.</p>
</dd>
</dl>
<p>{#deployment_start_date_time}</p>
<dl class="simple myst">
<dt><strong>Deployment Start Date Time (DD-MMM-YYYY HH:MM:SS)</strong></dt><dd><p>The date and time that a camera was placed for a specific deployment (e.g., 17-Jan-2018 10:34:22).</p>
</dd>
</dl>
<p>The Deployment Start Date Time may not coincide with when the first image or video was collected (i.e., the Image Set Start Date Time). Recording this field allows users to account for deployments where no images were captured and to confirm the first date and time a camera was active.</p>
<p>{#deployment_visit}</p>
<dl class="simple myst">
<dt>Deployment visit</dt><dd><p>When a crew has gone to a location to deploy a remote camera.</p>
</dd>
</dl>
<p>{#detection_event}</p>
<dl class="simple myst">
<dt>Detection “event”</dt><dd><p>A group of images or video clips that are considered independent from other images or video clips based on a certain time threshold (or “inter-detection interval”). For example, 30 minutes (O’Brien et al., 2003; Gerber et al., 2010; Kitamura et al., 2010; Samejima et al., 2012) or 1 hour (e.g., Tobler et al., 2008; Rovero &amp; Marshall, 2009).</p>
</dd>
</dl>
<p>{#detection_distance}</p>
<dl class="simple myst">
<dt>Detection distance</dt><dd><p>“The maximum distance that a sensor can detect a target” (Wearn and Glover-Kapfer, 2017).</p>
</dd>
</dl>
<p>{#detection_probability}</p>
<dl class="simple myst">
<dt>Detection probability (aka detectability)</dt><dd><p>The probability (likelihood) that an individual of the population of interest is included in the count at time or location <em>i</em>.</p>
</dd>
</dl>
<p>{#detection_rate}</p>
<dl class="simple myst">
<dt>Detection rate</dt><dd><p>The frequency of independent detections within a specified time period.</p>
</dd>
</dl>
<p>{#detection_zone}</p>
<dl class="simple myst">
<dt>Detection zone</dt><dd><p>The area (conical in shape) in which a remote camera can detect the heat signature and motion of an object (Rovero &amp; Zimmermann, 2016) (Figure 5).</p>
</dd>
</dl>
<p>{#mods_distance_sampling}</p>
<dl class="simple myst">
<dt>Distance sampling (DS) model (Howe et al., 2017)</dt><dd><p>A method to estimate abundance by using distances at which animals are detected (from survey lines or points) to model abundance as a function of decreasing detection probability with animal distance from the camera (using a decay function) (Cappelle et al., 2021; Howe et al., 2017).</p>
</dd>
</dl>
<p>{#easting_camera_location}</p>
<dl class="simple myst">
<dt><strong>Easting Camera Location</strong></dt><dd><p>The easting UTM coordinate of the camera location (e.g., “337875”). Record using the NAD83 datum. Leave blank if recording the Longitude instead.</p>
</dd>
</dl>
<p>{#effective_detection_distance}</p>
<dl class="simple myst">
<dt>Effective detection distance</dt><dd><p>The distance from a camera that would give the same number of detections if all animals up to that distance are perfectly detected, and no animals that are farther away are detected; Buckland, 1987, Becker et al., 2022).</p>
</dd>
</dl>
<p>{#event_type}</p>
<dl class="simple myst">
<dt><strong>Event Type</strong></dt><dd><p>Whether detections were reported as an individual image captured by the camera (“Image”), a “Sequence,” or “Tag.”</p>
</dd>
</dl>
<p>{#false_trigger}</p>
<dl class="simple myst">
<dt>False trigger</dt><dd><p>Blank images (no wildlife or human present). These images commonly occur when a camera is triggered by vegetation blowing in the wind.</p>
</dd>
</dl>
<p>{#field_of_view}</p>
<dl class="simple myst">
<dt>Field of View (FOV)</dt><dd><p>The extent of a scene that is visible in an image (Figure 5); a large FOV is obtained by “zooming out” from a scene, whilst “zooming in” will result in a smaller FOV (Wearn &amp; Glover-Kapfer, 2017).</p>
</dd>
</dl>
<p>{#settings_flash_output}</p>
<dl class="simple myst">
<dt>Flash output</dt><dd><p>The camera setting that provides the level of intensity of the flash (if enabled).</p>
</dd>
</dl>
<p>{#fov_target}</p>
<dl class="simple myst">
<dt><strong>FOV Target Feature</strong></dt><dd><p>A specific man-made or natural feature at which the camera is aimed to maximize the detection of wildlife species or to measure the use of that feature. Record “None” if a FOV Target Feature was not used and “Unknown” if not known. If “Other,” describe in the Camera Location Comments.</p>
</dd>
</dl>
<p>{#fov_target_distance}</p>
<dl class="simple myst">
<dt><strong>*FOV Target Feature Distance (m)</strong></dt><dd><p>The distance from the camera to the FOV Target Feature (in metres; to the nearest 0.5 m). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#gps_unit_accuracy}</p>
<dl class="simple myst">
<dt><strong>GPS Unit Accuracy (m)</strong></dt><dd><p>The margin of error of the GPS unit used to record spatial information (e.g., “5” [m]), such as the coordinates of the camera location. On most GPS units (e.g., “Garmin”) this information is provided on the unit’s satellite information page.</p>
</dd>
</dl>
<p>{#human_transport_mode_activity}</p>
<dl class="simple myst">
<dt><strong>*Human Transport Mode/Activity</strong></dt><dd><p>The activity performed or mode of transportation used by a human observed (e.g., hiker, skier, off-highway vehicle, etc.). This categorical field should be populated when data on humans (in addition to wildlife) are collected. Leave blank if not applicable and record “Unknown” if not known.</p>
</dd>
</dl>
<p>{#mods_hurdle}</p>
<dl class="simple myst">
<dt>Hurdle model (Mullahy, 1986; Heilbron 1994)</dt><dd><p>A regression model used in the setting of excess zeros (zero-inflation) and overdispersion (Mullahy, 1986). Hurdle models (aka “zero-altered” models) differ from zero-inflation models in that they are two-part models, and the zero and non-zero counts are modelling separately (thus, they are only adequate when the counting process cannot generate a zero value) (Blasco-Moreno et al., 2019). [relative abundance indices]</p>
</dd>
</dl>
<p>{#image}</p>
<dl class="simple myst">
<dt>Image</dt><dd><p>An individual image captured by a camera, which may be part of a multi-image sequence (recorded as “Image Name”).</p>
</dd>
</dl>
<p>{#image_classification}</p>
<dl class="simple myst">
<dt>Image classification</dt><dd><p>The process of assigning class labels to an image according to the wildlife species, other entities (e.g., human, vehicle), or conditions within the image. Image classification can be performed manually or automatically by an artificial intelligence (AI) algorithm. Image classification is sometimes used interchangeably with “image tagging.”</p>
</dd>
</dl>
<p>{#image_classification_confidence}</p>
<dl class="simple myst">
<dt>Image classification confidence</dt><dd><p>The likelihood of an image containing an object of a certain class (Fennell et al., 2022).</p>
</dd>
</dl>
<p>{#image_flash_output}</p>
<dl class="simple myst">
<dt><strong>*Image Flash Output</strong></dt><dd><p>The Image Flash Output is an image metadata field indicating the level of intensity of the flash [if enabled/applicable]). Record as reported in the image Exif data (e.g., “Flash Did Not Fire”, “Auto”). This field is in text format; record “Unknown” if not known; leave blank if not applicable.</p>
</dd>
</dl>
<p>{#image_infrared_illuminator}</p>
<dl class="simple myst">
<dt><strong>*Image Infrared Illuminator</strong></dt><dd><p>The Image Infrared Illuminator is an image metadata field indicating whether the infrared illuminator setting was enabled (if applicable; to obtain greater visibility at night by producing infrared light). Record as reported in the image Exif data (e.g., “On” or “Off”). This field is categorical; leave blank if not applicable and record “Unknown” if not known.</p>
</dd>
</dl>
<p>{#image_name}</p>
<dl class="simple myst">
<dt><strong>Image Name</strong></dt><dd><p>A unique alphanumeric identifier for the image. It is important to include (at a minimum) the camera location, date, time, and image number when generating an Image Name to avoid duplicate file names (e.g., “bh1_17-Jul-2018_P900FF04152022_22-Jul-2018 10:34:22_img_100” or “bh1_17-Jul-2018_22-Jul-2018_10:34:22_img_100”).</p>
</dd>
</dl>
<p>{#image_processing}</p>
<dl class="simple myst">
<dt>Image processing</dt><dd><p>The series of operations that are taken to extract information from images. In the case of remote camera data, it can include loading the images into a processing platform, extracting information from the image metadata (e.g., the date and time the image was taken), running an artificial intelligence (AI) algorithm to identify empty images, classifying animals or other entities within the image.</p>
</dd>
</dl>
<p>{#image_sequence}</p>
<dl class="simple myst">
<dt>Image Sequence</dt><dd><p>The order of the image in a rapid-fire sequence as reported in the image Exif data (text; e.g., “1 of 1” or “1 of 3”). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#image_set_end_date_time}</p>
<dl class="simple myst">
<dt><strong>Image Set End Date Time (DD-MMM-YYYY HH:MM:SS)</strong></dt><dd><p>The date and time of the last image or video collected during a specific deployment (e.g., “17-Jan-2018 22:10:05”).</p>
</dd>
<dd><p>The Image Set End Date Time may not coincide with the deployment end date time. Recording this field allows users to account for deployments that were conducted but for which no data was found and to confirm the last date and time a camera was active (if functioning) if no images or videos were captured prior to Service/Retrieval (especially valuable if users did not collect Time-lapse images or if the camera malfunctioned).</p>
</dd>
</dl>
<p>{#image_set_start_date_time}</p>
<dl class="simple myst">
<dt><strong>Image Set Start Date Time (DD-MMM-YYYY HH:MM:SS)</strong></dt><dd><p>The date and time of the first image or video collected during a specific deployment (e.g., “17-Jan-2018 12:00:02”).</p>
</dd>
<dd><p>The Image Set Start Date Time may not coincide with the Deployment Start Date Time. Recording this field allows users to confirm the first date and time a camera was active (reliable if Time-lapse images were collected; especially valuable if the user scheduled a start delay).</p>
</dd>
</dl>
<p>{#image_tagging}</p>
<dl class="simple myst">
<dt>Image tagging</dt><dd><p>The process of classifying an image according to the wildlife species, other entities (e.g., human, vehicle), or conditions within the image. Image tagging may follow image classification to further classify characteristics of the individuals (e.g., age class, sex class, or behaviour) or entities within the image.</p>
</dd>
</dl>
<p>{#image_trigger_mode}</p>
<dl class="simple myst">
<dt><strong>*Image Trigger Mode</strong></dt><dd><p>The type of trigger mode used to capture the image as reported in the image Exif data (e.g., “Time Lapse”, “Motion Detection,” “CodeLoc Not Entered,” “External Sensor”). Record “Unknown” if not known.</p>
</dd>
</dl>
<p>{#image_sequence_comments}</p>
<dl class="simple myst">
<dt><strong>*Image/Sequence Comments</strong></dt><dd><p>Comments describing additional details about the image/sequence.</p>
</dd>
</dl>
<p>{#image_sequence_date_time}</p>
<dl class="simple myst">
<dt><strong>Image/Sequence Date Time (DD-MMM-YYYY HH:MM:SS)</strong></dt><dd><p>The date and time of an image, or the image chosen to represent the sequence, recorded as “DD-MMM-YYYY HH:MM:SS” (e.g., 22-Jul-2018 11:02:02).</p>
</dd>
<dd><p>Sequence date/time information may be reported for a “representative image” of a sequence (i.e., the image with the most information). For example, if three images were included in a sequence, but the Sex Class could only be discerned in the second image [all else remaining equal], the second image would be the best representative image of the sequence.</p>
</dd>
<dd><p>The Image/Sequence Date Time differs from the Image Set Start Date Time which refers to the first image or video collected during a deployment.</p>
</dd>
</dl>
<p>{#imperfect_detection}</p>
<dl class="simple myst">
<dt>Imperfect detection</dt><dd><p>Species are often detected “imperfectly,” meaning that they are not always detected when they are present (e.g., due to cover of vegetation, cryptic nature or small size) (MacKenzie et al., 2004).</p>
</dd>
</dl>
<p>{#independent_detections}</p>
<dl class="simple myst">
<dt>Independent detections</dt><dd><p>Detections that are deemed to be independent based on a user-defined threshold (e.g., 30 minutes).</p>
</dd>
</dl>
<p>{#individual_count}</p>
<dl class="simple myst">
<dt><strong>Individual Count</strong></dt><dd><p>The number of unique individuals being categorized. Depending on the Event Type, this may be recorded as the total number of individuals, or according to Age Class and/or Sex Class.</p>
</dd>
</dl>
<p>{#settings_infrared_illum}</p>
<dl class="simple myst">
<dt>Infrared illuminator</dt><dd><p>The camera setting that can be enabled (if applicable to the camera make and camera model) to obtain greater visibility at night by producing infrared light. This field is categorical; leave blank if not applicable and record “Unknown” if not known.</p>
</dd>
</dl>
<p>{#mods_instantaneous_sampling}</p>
<dl class="simple myst">
<dt>Instantaneous sampling (IS) (Moeller et al., 2018)</dt><dd><p>A method used to estimate abundance or density from time-lapse images from randomly deployed cameras; the number of unique individuals (the count) is needed (Moeller et al., 2018).</p>
</dd>
</dl>
<p>{#intensity_of_use}</p>
<dl class="simple myst">
<dt>Intensity of use (Keim et al., 2019)</dt><dd><p>“The expected number of use events of a specific resource unit during a unit of time… [which characterizes] how frequently a particular resource unit is used” (Keim et al., 2019). The intensity of use differs from the probability of use (which characterizes “the probability of at least one use event of that resource unit during a unit of time”; Keim et al., 2019).</p>
</dd>
</dl>
<p>{#inter_detection_interval}</p>
<dl class="simple myst">
<dt>Inter-detection interval</dt><dd><p>A user-defined threshold used to define a single “detection event” (i.e., independent “events”) for group of images or video clips (e.g., 30 minutes or 1 hour). The threshold should be recorded in the Survey Design Description.</p>
</dd>
</dl>
<p>{#mods_inventory}</p>
<dl class="simple myst">
<dt>Inventory</dt><dd><p>Rapid assessment surveys to determine what species are present in a given area at a given point in time; there is no attempt made to quantify aspects of communities or populations (Wearn &amp; Glover-Kapfer, 2017).</p>
</dd>
</dl>
<p>{#age_class_juvenile}</p>
<dl class="simple myst">
<dt><strong>Juvenile</strong></dt><dd><p>Animals in their first summer, with clearly juvenile features (e.g., spots); mammals older than neonates but that still require parental care.</p>
</dd>
</dl>
<p>{#kernel_density_estimator}</p>
<dl class="simple myst">
<dt>Kernel density estimator</dt><dd><p>The probability of “utilization” (Jennrich &amp; Turner, 1969); describes the relative probability of use (Powell &amp; Mitchell, 2012).</p>
</dd>
</dl>
<p>{#key_id}</p>
<dl class="simple myst">
<dt><strong>*Key ID</strong></dt><dd><p>The unique ID for the specific key or set of keys used to lock/secure the camera to the post, tree, etc.</p>
</dd>
</dl>
<p>{#latitude_camera_location}</p>
<dl class="simple myst">
<dt><strong>Latitude Camera Location</strong></dt><dd><p>The latitude of the camera location in decimal degrees to five decimal places (e.g., “53.78136”). Leave blank if recording Northing instead.</p>
</dd>
</dl>
<p>{#longitude_camera_location}</p>
<dl class="simple myst">
<dt><strong>Longitude Camera Location</strong></dt><dd><p>The longitude of the camera location in decimal degrees to five decimal places (e.g., “-113.46067”). Leave blank if recording Easting instead.</p>
</dd>
</dl>
<p>{#baitlure_lure}</p>
<dl class="simple myst">
<dt>Lure</dt><dd><p>Any substance that draws animals closer; lures include scent (olfactory) lure, visual lure and audible lure (Schlexer, 2008).</p>
</dd>
</dl>
<p>{#typeid_marked}</p>
<dl class="simple myst">
<dt>Marked individuals / populations / species</dt><dd><p>Individuals, populations, or species (varies with modelling approach and context) that can be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars).</p>
</dd>
</dl>
<p>{#mods_mr}</p>
<dl class="simple myst">
<dt>Mark-resight (MR) model (Arnason et al., 1991; McClintock et al., 2009)</dt><dd><p>A method used to estimate the abundance of partially marked populations using the number of marked individuals, the number of unmarked individuals, and the detection probability from marked animals (Wearn &amp; Glover-Kapfer, 2017). MR is similar to capture-recapture (CR; Karanth, 1995; Karanth &amp; Nichols, 1998) models, except only a portion of animals are individually identified.</p>
</dd>
</dl>
<p>{#metadata}</p>
<dl class="simple myst">
<dt>Metadata</dt><dd><p>Data that provides information about other data (e.g., the number of images on an SD card).</p>
</dd>
</dl>
<p>{#mods_modelling_assumption}</p>
<dl class="simple myst">
<dt>Model assumption</dt><dd><p>Explicitly stated (or implicitly premised) conventions, choices and other specifications (e.g., about the data, wildlife ecology/behaviour, the relationships between variables, etc.) on which a particular modelling approach is based that allows the model to provide valid inference.</p>
</dd>
</dl>
<p>{#mods_modelling_approach}</p>
<dl class="simple myst">
<dt>Modelling approach</dt><dd><p>The method used to analyze the camera data, which should depend on the state variable, e.g., occupancy models [MacKenzie et al., 2002], spatially explicit capture recapture (SECR) for density estimation [Chandler and Royle, 2013], etc. and the Target Species.</p>
</dd>
</dl>
<p>{#settings_motion_image_interval}</p>
<dl class="simple myst">
<dt><strong>Motion Image Interval (seconds)</strong></dt><dd><p>The time (in seconds) between images within a multi-image sequence that occur due to motion, heat, or activation of external detector devices. The Motion Image Interval is pre-set in the camera’s settings by the user, but the time at which the camera collects images because of this setting is influenced by the presence of movement or heat. For example, if the camera was set to take 3 images per event at a Motion Image Interval of 3 seconds when the camera detects motion or heat, the first image will be collected (e.g., at 09:00:00), the second image will be collected 3 seconds later (09:00:03), and the third will be collected 3 seconds after that (09:00:06).</p>
</dd>
<dd><p>This setting differs from the Quiet Period in that the delay occurs between images contained within a multi-image sequence, rather than between multi-image sequences (as in Quiet Period). If a Motion Image Interval was not set, enter “0” seconds (i.e., instantaneous).</p>
</dd>
</dl>
<p>{#mods_negative_binomial}</p>
<dl class="simple myst">
<dt>Negative binomial (NB) regression (Mullahy, 1986)</dt><dd><p>A regression model used for count data with overdispersion but without zero-inflation. [relative abundance indices]</p>
</dd>
</dl>
<p>{#mods_n_mixture}</p>
<dl class="simple myst">
<dt>N-mixture models</dt><dd><p>A class of models for estimating absolute abundance using replicated counts of animals from several different sites; site-specific counts are treated as independent random variables to estimate the number of animals available for capture at each site; detection is imperfect (Royle 2004). N-mixture models are a type of site-structured model (i.e., that “treat each camera as though it samples… [a] distinct population within a larger meta-population” [Clarke et al., 2023]).</p>
</dd>
</dl>
<p>{#northing_camera_location}</p>
<dl class="simple myst">
<dt><strong>Northing Camera Location</strong></dt><dd><p>The northing UTM coordinate of the camera location (e.g., “5962006”). Record using the NAD83 datum. Leave blank if recording the Latitude instead.</p>
</dd>
</dl>
<p>{#occupancy}</p>
<dl class="simple myst">
<dt>Occupancy</dt><dd><p>The probability a site is occupied by the species.</p>
</dd>
</dl>
<p>{#mods_occupancy}</p>
<dl class="simple myst">
<dt>Occupancy model (MacKenzie et al., 2002)</dt><dd><p>A modelling approach used to account for imperfect detection by first evaluating the detection probability of a species via detection histories (i.e., present or absent) to determine the probability of the true presence or absence of a species at a site (MacKenzie et al., 2002).</p>
</dd>
</dl>
<p>{#mods_overdispersion}</p>
<dl class="simple myst">
<dt>Overdispersion</dt><dd><p>A variance significantly larger than the mean (Bliss &amp; Fisher, 1953); greater variability in a set of data than predicted by the error structure of the model (Harrison et al., 2018); excess variability can be caused by zero inflation, non-independence of counts, or both (Zuur et al., 2009).</p>
</dd>
</dl>
<p>{#sampledesign_paired}</p>
<dl class="simple myst">
<dt>Paired design</dt><dd><p>A form of “clustered design” where two cameras that are placed closely together to increase detection probability (“paired cameras”), to evaluate certain conditions (“paired sites”, e.g., on- or off trails), etc. Paired placements can help to account for other variability that might occur (i.e., variation in habitat quality). For some objectives, pairs of cameras might be considered subsamples within another sampling design (e.g., simple random, stratified random, systematic).</p>
</dd>
</dl>
<p>{#typeid_partially_marked}</p>
<dl class="simple myst">
<dt>Partially marked individuals / populations / species</dt><dd><p>Individuals, populations, or species (varies with modelling approach and context) that have a suite of partially identifying traits (e.g., antler points, sex class, age class). For populations/species, those in which a proportion of individuals carry marks or in which individuals themselves are partially marked.</p>
</dd>
</dl>
<p>{#settings_photos_per_trigger}</p>
<dl class="simple myst">
<dt><strong>Photos Per Trigger</strong></dt><dd><p>The camera setting that describes the number of photos taken each time the camera is triggered.</p>
</dd>
</dl>
<p>{#mods_poisson}</p>
<dl class="simple myst">
<dt>Poisson regression</dt><dd><p>A regression model for count data used when data are not overdispersed or zero-inflated (Lambert, 1992). [relative abundance indices]</p>
</dd>
</dl>
<p>{#project}</p>
<dl class="simple myst">
<dt>Project</dt><dd><p>A scientific study, inventory or monitoring program that has a certain objective, defined methods, and a defined boundary in space and time (recorded as “Project Name”).</p>
</dd>
</dl>
<p>{#project_coordinator}</p>
<dl class="simple myst">
<dt><strong>Project Coordinator</strong></dt><dd><p>The first and last name of the primary contact for the project.</p>
</dd>
</dl>
<p>{#project_coordinator_email}</p>
<dl class="simple myst">
<dt><strong>Project Coordinator Email</strong></dt><dd><p>The email address of the Project Coordinator.</p>
</dd>
</dl>
<p>{#project_description}</p>
<dl class="simple myst">
<dt><strong>Project Description</strong></dt><dd><p>A description of the project objective(s) and general methods.</p>
</dd>
</dl>
<p>{#project_name}</p>
<dl class="simple myst">
<dt><strong>Project Name</strong></dt><dd><p>A unique alphanumeric identifier for each project. Ideally, the Project Name should include an abbreviation for the organization, a brief project name, and the year the project began (e.g., “uofa_oilsands_2018”).</p>
</dd>
</dl>
<!--. 
-->
<p>{#pseudoreplication}</p>
<dl class="simple myst">
<dt>Pseudoreplication</dt><dd><p>When observations are not statistically independent (spatially or temporally) but are treated as if they are independent.</p>
</dd>
</dl>
<p>{#purpose_of_visit}</p>
<dl class="simple myst">
<dt><strong>Purpose of Visit</strong></dt><dd><p>The reason for visiting the camera location (i.e. to deploy the camera [“Deployment”], retrieve the camera [“Retrieve”] or to change batteries/SD card or replace the camera [“Service”]).</p>
</dd>
</dl>
<p>{#settings_quiet_period}</p>
<dl class="simple myst">
<dt><strong>Quiet Period (seconds)</strong></dt><dd><p>The user-defined camera setting which provides the time (in seconds) between shutter “triggers” if the camera was programmed to pause between firing initially and firing a second time. If a Quiet Period was not set, enter “0.”</p>
</dd>
<dd><p>Also known as “time lag” (depending on the Camera Make and Camera Model; Palmer et al., 2018). The Quiet Period differs from the Motion Image Interval in that the delay occurs between multi-image sequences rather than between the images contained within multi-image sequences (as in the Motion Image Interval).</p>
</dd>
</dl>
<p>{#sampledesign_random}</p>
<dl class="simple myst">
<dt>Random (or “simple random”) design</dt><dd><p>Cameras occur at randomized camera locations (or sample stations) across the area of interest, sometimes with a predetermined minimum distance between camera locations (or sample stations).</p>
</dd>
</dl>
<p>{#mods_rest}</p>
<dl class="simple myst">
<dt>Random encounter and staying time (REST) model (Nakashima et al., 2018)</dt><dd><p>A recent modification of the REM (Nakashima et al., 2018) that substitutes staying time (i.e., the cumulative time in the cameras’ detection zone) for movement speed (staying time and movement speed are inversely proportional) (Cappelle et al., 2021).</p>
</dd>
</dl>
<p>{#mods_rem}</p>
<dl class="simple myst">
<dt>Random encounter model (REM) (Rowcliffe et al., 2008, 2013)</dt><dd><p>A method used to estimate the density of unmarked populations; uses the rate of independent captures, an estimate of movement rate, average group size, and the area sampled by the remote camera.</p>
</dd>
</dl>
<p>{#recovery_time}</p>
<dl class="simple myst">
<dt>Recovery time</dt><dd><p>The time necessary for the camera to prepare to capture the next photo after the previous one has been recorded (Trolliet et al., 2014).</p>
</dd>
</dl>
<p>{#fov_registration_area}</p>
<dl class="simple myst">
<dt>Registration area</dt><dd><p>The area in which an animal entering has at least some probability of being captured on the image.</p>
</dd>
</dl>
<p>{#mods_relative_abundance}</p>
<dl class="simple myst">
<dt>Relative abundance indices</dt><dd><p>An index of relative abundance. When observational data is converted to a detection rate (i.e., the frequency [count] of independent detections of a species within a distinct time period). An index can be a count of animals or any sign that is expected to vary with population size (Caughley, 1977; O’Brien, 2011).</p>
</dd>
</dl>
<p>{#remaining_battery_percent}</p>
<dl class="simple myst">
<dt><strong>*Remaining Battery (%)</strong></dt><dd><p>The remaining battery power (%) of batteries within a camera.</p>
</dd>
</dl>
<p>{#mods_royle_nichols}</p>
<dl class="simple myst">
<dt>Royle-Nichols model (Royle &amp; Nichols, 2003; MacKenzie et al., 2006)</dt><dd><p>A method used to estimate population abundance or density, which assumes that individuals are counted only once per sampling occasion (Royle, 2004), but that does not require all individuals to be marked. Royle-Nichols models are a type of site-structured model (i.e., that “treat each camera as though it samples… [a] distinct population within a larger meta-population” [Clarke et al., 2023]).</p>
</dd>
</dl>
<p>{#sample_station}</p>
<dl class="simple myst">
<dt>Sample station</dt><dd><p>A grouping of two or more non-independent camera locations, such as when cameras are clustered or paired (recorded as “Sample Station Name”).</p>
</dd>
</dl>
<p>{#sample_station_name}</p>
<dl class="simple myst">
<dt><strong>Sample Station Name</strong></dt><dd><p>A sequential alphanumeric identifier for each grouping of two more non-independent camera locations (when cameras are deployed in clusters, pairs, or arrays; e.g., “ss1” in “ss1_bh1”, “ss1_bh2”, “ss1_bh3” etc.). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#baitlure_scent_lure}</p>
<dl class="simple myst">
<dt>Scent lure</dt><dd><p>Any material that draws animals closer via their sense of smell (Schlexer, 2008).</p>
</dd>
</dl>
<p>{#sd_card_id}</p>
<dl class="simple myst">
<dt><strong>*SD Card ID</strong></dt><dd><p>The ID label on an SD card (e.g., “cmu_100”).</p>
</dd>
</dl>
<p>{#sd_card_replaced}</p>
<dl class="simple myst">
<dt><strong>*SD Card Replaced</strong></dt><dd><p>Whether the SD card was replaced.</p>
</dd>
</dl>
<p>{#sd_card_status}</p>
<p><strong>*SD Card Status (% Full)</strong></p>
<p>The remaining storage capacity on an SD card; collected during a camera service or retrieval.</p>
<p>{#security}</p>
<dl class="simple myst">
<dt><strong>*Security</strong></dt><dd><p>The equipment used to secure the camera (e.g., “Security box,” “Bracket,” “Bracket + Screws,” or “None”).</p>
</dd>
</dl>
<p>{#sequence}</p>
<dl class="simple myst">
<dt>Sequence</dt><dd><p>A user-defined group of images or video clips considered as a single “detection event” (recorded as “Sequence Name”); often users choose a certain time threshold (or “inter-detection interval”) to define independent “events”; e.g., 30 minutes or 1 hour. The threshold should be recorded in the Survey Design Description).</p>
</dd>
</dl>
<p>{#sequence_name}</p>
<dl class="simple myst">
<dt><strong>Sequence Name</strong></dt><dd><p>A unique alphanumeric identifier for a multi-image sequence. The Sequence Name should ideally consist of the Deployment Name and the names of the first and last images and videos in the sequence (separated by “_”) (i.e., “Deployment Name”,_“,img_#[name of first image in sequence],”_”,img_#[name of last image in sequence] (e.g., “bh1_22-Jul-2018_img_001-img_005”). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#service_retrieval}</p>
<dl class="simple myst">
<dt>Service/Retrieval</dt><dd><p>When a crew has gone to a location to service or retrieve a remote camera.</p>
</dd>
</dl>
<p>{#service_retrieval_comments}</p>
<dl class="simple myst">
<dt><strong>*Service/Retrieval Comments</strong></dt><dd><p>Comments describing additional details about the service/retrieval.</p>
</dd>
</dl>
<p>{#service_retrieval_crew}</p>
<dl class="simple myst">
<dt><strong>Service/Retrieval Crew</strong></dt><dd><p>The first and last names of the individuals who collected data during the service/retrieval visit.</p>
</dd>
</dl>
<p>{#service_retrieval_metadata}</p>
<dl class="simple myst">
<dt>Service/retrieval metadata</dt><dd><p>Metadata that should be collected each time a camera location is visited to service or retrieve a camera, including data on any change to the camera location, sampling period, and/or setting type (e.g., not baited and then baited later). The relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved.</p>
</dd>
<dd><p>Refer to Appendix - Table A5 and the Camera Service/Retrieval Field Datasheet.</p>
</dd>
</dl>
<p>{#service_retrieval_visit}</p>
<dl class="simple myst">
<dt>Service/Retrieval visit</dt><dd><p>When a crew has gone to a location to service or retrieve a remote camera.</p>
</dd>
</dl>
<p>{#sex_class}</p>
<dl class="simple myst">
<dt><strong>Sex Class</strong></dt><dd><p>The sex classification of individual(s) being categorized (e.g., “Male,” “Female,” or “Unknown”).</p>
</dd>
</dl>
<p>{#mods_ste}</p>
<dl class="simple myst">
<dt>Space-to-event (STE) model (Moeller et al., 2018)</dt><dd><p>A method used to estimate abundance or density that accounts for variable detection probability through the use of time-lapse images and is unaffected by animal movement rates (collapses sampling intervals to an instant in time, and thus estimates are unaffected by animal movement rates) (Moeller et al., 2018).</p>
</dd>
</dl>
<p>{#spatial_autocorrelation}</p>
<dl class="simple myst">
<dt>Spatial autocorrelation</dt><dd><p>The tendency for locations that are closer together to be more similar.</p>
</dd>
</dl>
<p>{#mods_sc}</p>
<dl class="simple myst">
<dt>Spatial count (SC) model / Unmarked spatial capture-recapture (Chandler &amp; Royle, 2013)</dt><dd><p>A method used to estimate the density of unmarked populations; similar to SECR (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009); however, SC models account for individuals’ unknown identities using the spatial pattern of detections (Chandler &amp; Royle, 2013; Sun et al., 2022). SC uses trap-specific counts to estimate the location and number of activity centres to estimate density.</p>
</dd>
</dl>
<p>{#mods_smr}</p>
<dl class="simple myst">
<dt>Spatial mark-resight (SMR) (Chandler &amp; Royle, 2013; Sollmann et al., 2013a, 2013b)</dt><dd><p>A method used to estimate the density of “partially marked populations by combining… [detection] histories of marked [individuals] and counts of unmarked [individuals]” (Doran-Myers, 2018) over several occasions (Sollman et al., 2013a; Rich et al., 2014; Whittington et al., 2018). SMR models can be implemented using different statistical frameworks, including Bayesian estimation (Royle and Young, 2008; Morin et al., 2022).</p>
</dd>
</dl>
<p>{#mods_2flankspim}</p>
<dl class="simple myst">
<dt>Spatial partial identity model (2-flank SPIM) (Augustine et al., 2018)</dt><dd><p>A method used to estimate the density of partially marked populations in which the “spatial locations of where partial identity samples are captured to probabilistically resolve their complete identities” (Augustine et al., 2018). Paired sampling design is commonly used to capture both the right and left flanks of an animal to resolve individual identities (Augustine et al., 2018). 2-flank SPIM is an extension of the SCR model (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009).</p>
</dd>
</dl>
<p>{#mods_scr_secr}</p>
<dl class="simple myst">
<dt>Spatially explicit capture-recapture (SECR) / Spatial capture-recapture (SCR) (Borchers &amp; Efford, 2008; Efford, 2004; Royle &amp; Young, 2008; Royle et al., 2009)</dt><dd><p>The SECR (or SCR) method is used to estimate the density of marked populations; an extension of traditional capture-recapture (CR; Karanth, 1995; Karanth &amp; Nichols, 1998) models (Karanth, 1995; Karanth &amp; Nichols, 1998) that explicitly accounts for camera location and animal movement (Burgar et al., 2018). SECR models use spatially referenced individual capture histories to infer where animals’ home range centres are, assuming that detection probability decreases with increasing distance between cameras and home range centres (Clarke et al., 2023). SECR models can be implemented using different statistical frameworks, including Bayesian estimation (Royle and Young, 2008; Morin et al., 2022).</p>
</dd>
</dl>
<p>{#species}</p>
<dl class="simple myst">
<dt><strong>Species</strong></dt><dd><p>The capitalized common name of the species being categorized (“tagged”).</p>
</dd>
</dl>
<p>{#stake_distance}</p>
<dl class="simple myst">
<dt><strong>*Stake Distance (m)</strong></dt><dd><p>The distance from the camera to a stake (in metres to the nearest 0.05 m). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#state_variable}</p>
<dl class="simple myst">
<dt>State variable</dt><dd><p>A formal measure that summarizes the state of a community or population at a particular time (Wearn &amp; Glover-Kapfer, 2017), e.g., species richness or population abundance.</p>
</dd>
</dl>
<p>{#sampledesign_stratified}</p>
<dl class="simple myst">
<dt>Stratified design</dt><dd><p>The area of interest is divided into smaller strata (e.g., habitat type, disturbance levels), and cameras are placed within each stratum (e.g., 15%, 35% and 50% of sites within high, medium, and low disturbance strata).</p>
</dd>
</dl>
<p>{#sampledesign_stratified_random}</p>
<dl class="simple myst">
<dt>Stratified random design</dt><dd><p>The area of interest is divided into smaller strata (e.g., habitat type, disturbance levels), and then a proportional random sample of sites is selected within each stratum (e.g., 15%, 35% and 50% of sites within high, medium and low disturbance strata).</p>
</dd>
</dl>
<p>{#study_area}</p>
<dl class="simple myst">
<dt>Study area</dt><dd><p>A unique research, inventory or monitoring area (spatial boundary) within a project (there may be multiple study areas within a single project) (recorded as “Study Area Name”).</p>
</dd>
</dl>
<p>{#study_area_description}</p>
<dl class="simple myst">
<dt><strong>Study Area Description</strong></dt><dd><p>A description for each unique research or monitoring area including its location, the habitat type(s), land use(s) and habitat disturbances (where applicable).</p>
</dd>
</dl>
<p>{#study_area_name}</p>
<dl class="simple myst">
<dt><strong>Study Area Name</strong></dt><dd><p>A unique alphanumeric identifier for each study area (e.g.,”oilsands_ref1”). If only one area was surveyed, the Project Name and Study Area Name should be the same.</p>
</dd>
</dl>
<p>{#age_class_subadult}</p>
<dl class="simple myst">
<dt><strong>Subadult</strong></dt><dd><p>Animals older than a “Juvenile” but not yet an “Adult”; a “Subadult” may be further classified into “Young of the Year” or “Yearling.”</p>
</dd>
</dl>
<p>{#age_class_subadult_yearling}</p>
<dl class="simple myst">
<dt><strong>Subadult - Yearling</strong></dt><dd><p>Animals approximately one year old; has lived through one winter season; between “Young of Year” and “Adult.”</p>
</dd>
</dl>
<p>{#age_class_subadult_youngofyear}</p>
<dl class="simple myst">
<dt><strong>Subadult - Young of Year</strong></dt><dd><p>Animals less than one year old; born in the previous year’s spring, but has not yet lived through a winter season; between “Juvenile” and “Yearling.”</p>
</dd>
</dl>
<!--. 
-->
<p>{#survey}</p>
<dl class="simple myst">
<dt>Survey</dt><dd><p>A unique deployment period (temporal extent) within a project (recorded as “Survey Name”).</p>
</dd>
</dl>
<!--. 
-->
<p>{#survey_design}</p>
<dl class="simple myst">
<dt><strong>Survey Design</strong></dt><dd><p>The spatial arrangement of remote cameras within the study area for an individual survey. If “Hierarchical (multiple)*”, include additional details in the Survey Design Description.</p>
</dd>
<dd><p>Note that we refer to different configurations of cameras more generally as study design and sampling design; however, the term “Survey Design” refers to study design as it applies to an individual survey. There may be multiple Survey Designs for surveys within a project; if this occurs, the Survey Design should be reported separately for each survey.</p>
</dd>
</dl>
<p>{#survey_design_description}</p>
<dl class="simple myst">
<dt><strong>*Survey Design Description</strong></dt><dd><p>A description of any additional details about the Survey Design.</p>
</dd>
</dl>
<p>{#survey_name}</p>
<dl class="simple myst">
<dt><strong>Survey Name</strong></dt><dd><p>A unique alphanumeric identifier for each survey period (e.g., “fortmc_001”).</p>
</dd>
</dl>
<p>{#survey_objectives}</p>
<dl class="simple myst">
<dt><strong>Survey Objectives</strong></dt><dd><p>The specific objectives of each survey within a project, including the Target Species, the state variables (e.g., occupancy, density), and proposed modelling approach(es). Survey Objectives should be specific, measurable, achievable, relevant, and time-bound (i.e., SMART).</p>
</dd>
</dl>
<p>{#sampledesign_systematic}</p>
<dl class="simple myst">
<dt>Systematic design</dt><dd><p>Camera locations occur in a regular pattern (e.g., a grid pattern) across the study area.</p>
</dd>
</dl>
<p>{#sampledesign_systematic_random}</p>
<dl class="simple myst">
<dt>Systematic random design</dt><dd><p>Camera locations are selected using a two-stage approach. Firstly, girds are selected systematically (to occur within a regular pattern) across the study area. The location of the camera within each grid is then selected randomly.</p>
</dd>
</dl>
<p>{#tag}</p>
<dl class="simple myst">
<dt><strong>Tag</strong></dt><dd><p>When individuals, or groups of individuals, are categorized within an image, regardless of whether the information applies to all of the individuals in the image. A single tag is applied to categorize one or more individuals with the same combination of characteristics (e.g., Adult Males displaying the same Behaviour). Conversely, multiple tags are applied when individuals in an image differ in their characteristics (e.g., an Adult and a Juvenile, all else remaining equal, are tagged separately). This could also occur for Age Class, Behaviour, Human Transport Mode/Activity, etc. Since multiple tags can occur for a single image, there may be multiple data rows for the same image (if the Event Type is at the “Tag” level).</p>
</dd>
</dl>
<p>{#target_species}</p>
<dl class="simple myst">
<dt><strong>Target Species</strong></dt><dd><p>The common name(s) of the species that the survey was designed to detect.</p>
</dd>
</dl>
<p>{#sampledesign_targeted}</p>
<dl class="simple myst">
<dt>Targeted design</dt><dd><p>Camera locations or sample stations are placed in areas that are known or suspected to have higher activity levels (e.g., game trails, mineral licks).</p>
</dd>
</dl>
<p>{#test_image}</p>
<dl class="simple myst">
<dt>Test image</dt><dd><p>An image taken from a camera after it has been set up to provide a permanent record of the visit metadata (e.g., Sample Station Name, Camera Location Name, Deployment Name, Crew, and Deployment Start Date Time [DD-MMM-YYYY HH:MM:SS]).</p>
</dd>
<dd><p>Taking a test image can be useful to compare the information from the image to that of which was collected on the Camera Service/Retrieval Field Datasheet after retrieval and can help in reducing recording errors.</p>
</dd>
</dl>
<p>{#test_image_taken}</p>
<dl class="simple myst">
<dt><strong>*Test Image Taken</strong></dt><dd><p>Whether a test image (i.e., an image taken from a camera after it has been set up to provide a permanent record of the visit metadata) was taken. Arm the camera, from ~5 m in front, walk towards the camera while holding the Test Image Sheet.</p>
</dd>
<dt>{#mods_tifc}</dt><dd><p>Time in front of the camera (TIFC) (Huggard, 2018; Warbington &amp; Boyce, 2020; tested in Becker et al., 2022)</p>
</dd>
<dd><p>A method used to estimate density that treats camera image data as quadrat samples (Becker et al., 2022).</p>
</dd>
</dl>
<p>{#timelapse_image}</p>
<dl class="simple myst">
<dt>Time-lapse image</dt><dd><p>Images that are taken at regular intervals (e.g., hourly or daily, on the hour). It is critical to take a minimum of one time-lapse image per day at a consistent time (e.g., 12:00 pm [noon]) to create a record of camera functionality and local environmental conditions (e.g., snow cover, plant growth, etc.). Time-lapse images may always be useful for modelling approaches that require estimation of the “viewshed” (“viewshed density estimators” such as REM or time-to-event (TTE) models; see Moeller et al., [2018] for advantages and disadvantages).</p>
</dd>
</dl>
<p>{#mods_tte}</p>
<dl class="simple myst">
<dt>Time-to-event (TTE) model (Moeller et al., 2018)</dt><dd><p>A method used to estimate abundance or density from the detection rate while accounting for animal movement rates (Moeller et al., 2018). The TTE model assumes perfect detection (though there is a model extension to account for imperfect detection that requires further testing).</p>
</dd>
</dl>
<p>{#total_number_of_camera_days}</p>
<dl class="simple myst">
<dt>Total number of camera days</dt><dd><p>The number of days that all cameras were active during the survey.</p>
</dd>
</dl>
<p>{#trigger_event}</p>
<dl class="simple myst">
<dt>Trigger “event”</dt><dd><p>An activation of the camera detector(s) that initiates the capture of a single or multiple images, or the recording of video.</p>
</dd>
</dl>
<p>{#settings_trigger_modes}</p>
<dl class="simple myst">
<dt><strong>Trigger Mode(s)</strong> (camera settings)</dt><dd><p>The camera setting(s) that determine how the camera will triggerby motion (“Motion Image”), at set intervals (“Time-lapse image”), and/or by video (“Video”; possible with newer camera models, such as Reconyx HP2X).</p>
</dd>
</dl>
<p>{#settings_trigger_sensitivity}</p>
<dl class="simple myst">
<dt><strong>Trigger Sensitivity</strong></dt><dd><p>The camera setting responsible for how sensitive a camera is to activation (to “triggering”) via the infrared and/or heat detectors (if applicable, e.g., Reconyx HyperFire cameras have a choice between “Low,” “Low/Med,” “Med,” “Med/High,” “High,” “Very high” and “Unknown”).</p>
</dd>
</dl>
<p>{#trigger_speed}</p>
<dl class="simple myst">
<dt>Trigger speed</dt><dd><p>The time delay necessary for the camera to shoot a photo once an animal has interrupted the infrared beam within the camera’s detection zone (Trolliet et al., 2014). Trigger speed differs from Motion Image Interval (a camera setting specified by the user) in that the trigger speed is inherent to the Camera Make and Camera Model (e.g., two different cameras, models both with a Motion Image Interval set to “no delay,” may not be able to capture images at the same speed).</p>
</dd>
</dl>
<p>{#typeid_unmarked}</p>
<dl class="simple myst">
<dt>Unmarked individuals / populations / species</dt><dd><p>Individuals, populations, or species (varies with modelling approach and context) that cannot be identified using natural or artificial markings (e.g., coat patterns, scars, tags, collars). Unmarked population models rely on supplementary data (e.g., animal movement speed) and/or assumptions as a surrogate for individual identification; that is, to distinguish between multiple detections of the same individual from detections of multiple individuals when individuals do not have unique features (Gilbert et al., 2020; Morin et al., 2022).</p>
</dd>
</dl>
<p>{#settings_userlabel}</p>
<dl class="simple myst">
<dt>User label</dt><dd><p>A label (up to 16 characters) that can be programmed in the camera’s settings, and that will be visible in the data band of all photos and videos taken by the camera (Reconyx, 2018). It is recommended that users program the Sample Station Name/Camera Location Name as the user label, which serves as a means to confirm which Sample Station Name/Camera Location Name is associated with the images/videos.</p>
</dd>
</dl>
<p>{#utm_zone_camera_location}</p>
<dl class="simple myst">
<dt><strong>UTM Zone Camera Location</strong></dt><dd><p>The number corresponding to the Universal Transverse Mercator (UTM) grid zone where the camera was placed (e.g., “12”). UTM is a coordinate system that divides the earth into grid zones that are identified with a number (representing a width of latitude) and letter (representing the hemisphere).</p>
</dd>
<dd><p>In Alberta the UTM zones are either 11, 12, or TTM. Enter all other UTM zones in the Camera Location Comments field (e.g., zones 7-10 for British Columbia), or use Latitude and Longitude instead of UTM coordinates.</p>
</dd>
</dl>
<p>{#settings_video_length}</p>
<dl class="simple myst">
<dt><strong>*Video Length (seconds)</strong></dt><dd><p>If applicable, describes the camera setting that specifies the minimum video duration (in seconds) that the camera will record when triggered. Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#fov_viewshed}</p>
<dl class="simple myst">
<dt>Viewshed</dt><dd><p>The area visible to the camera as determined by its lens angle (in degrees) and trigger distance (Moeller et al., 2023).</p>
</dd>
</dl>
<p>{#fov_viewshed_density_estimators}</p>
<dl class="simple myst">
<dt>Viewshed density estimators</dt><dd><p>Methods used to estimate the abundance of unmarked populations from observations of animals that relate animal observations to the space directly sampled by each camera’s viewshed (Moeller et al., 2023); they result in viewshed density estimates that can be extrapolated to abundance within broader sampling frames (Gilbert et al., 2020; Moeller et al., 2023).</p>
</dd>
</dl>
<p>{#visit}</p>
<dl class="simple myst">
<dt>Visit</dt><dd><p>When a crew has gone to a location to deploy, service, or retrieve a remote camera.</p>
</dd>
</dl>
<p>{#visit_comments}</p>
<dl class="simple myst">
<dt><strong>*Visit Comments</strong></dt><dd><p>Comments describing additional details about the deployment and/or service/retrieval visits.</p>
</dd>
</dl>
<p>{#visit_metadata}</p>
<dl class="simple myst">
<dt>Visit metadata</dt><dd><p>Metadata that should be collected each time a camera location is visited to deploy, service or retrieve a camera. Other relevant metadata fields that should be collected differ when a camera is deployed vs. serviced or retrieved. <br/>Refer to Appendix A - Table A5, Camera Deployment Field Datasheet, and Camera Service/Retrieval Field Datasheet.</p>
</dd>
</dl>
<p>{#baitlure_visual_lure}</p>
<dl class="simple myst">
<dt>Visual lure</dt><dd><p>Any material that draws animals closer via their sense of sight (Schlexer, 2008).</p>
</dd>
</dl>
<p>{#walktest}</p>
<dl class="simple myst">
<dt>Walktest</dt><dd><p>A test performed to ensure the camera height, tilt, etc., adequately captures the desired detection zone. The user will 1) activate the walktest mode, 2) attach the camera at the desired height / angle, 3) walk in front of the camera to a specified distance (i.e., the “Walktest Distance,” e.g., 5 m), and 4) wave their hand in front of the camera (usually at ground level and a chosen height [i.e., the “Walktest Height,” e.g., 0.8 m]) to determine if the camera is activating (a light on the camera will flash).</p>
</dd>
</dl>
<p>{#walktest_complete}</p>
<dl class="simple myst">
<dt><strong>*Walktest Complete</strong></dt><dd><p>Whether a walktest was performed to ensure the camera height, tilt, etc., adequately captures the desired detection zone. The user will 1) activate the walktest mode, 2) attach the camera at the desired height / angle, 3) walk in front of the camera to a specified distance (i.e., the “Walktest Distance,” e.g., 5 m), and 4) wave their hand in front of the camera (usually at ground level and a chosen height [i.e., the “Walktest Height,” e.g., 0.8 m]) to determine if the camera is activating (a light on the camera will flash).</p>
</dd>
</dl>
<p>{#walktest_distance}</p>
<dl class="simple myst">
<dt><strong>Walktest Distance (m)</strong></dt><dd><p>The horizontal distance from the camera at which the crew performs the walktest (metres; to the nearest 0.05 m). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#walktest_height}</p>
<dl class="simple myst">
<dt><strong>Walktest Height (m)</strong></dt><dd><p>The vertical distance from the camera at which the crew performs the walktest (metres; to the nearest 0.05 m). Leave blank if not applicable.</p>
</dd>
</dl>
<p>{#mods_zinb}</p>
<dl class="simple myst">
<dt>Zero-inflated negative binomial (ZINB) regression (McCullagh &amp; Nelder, 1989)</dt><dd><p>A regression model used in the setting of excess zeros (zero-inflation) and overdispersion. This approach is a two-part model, where the zero-inflation is modelled separately from the counts and assumes that the count (abundance) is “conditional” on the zero-inflation model (occurrence) model. [relative abundance indices]</p>
</dd>
</dl>
<p>{#mods_zip}</p>
<dl class="simple myst">
<dt>Zero-inflated Poisson (ZIP) regression (Lambert, 1992)</dt><dd><p>A regression model for count data that both follows the Poisson distribution and contains excess zeros (Lambert, 1992). ZIP models are only appropriate for data for which the overdispersion is not solely due to zero-inflation. [relative abundance indices]</p>
</dd>
</dl>
<p>{#mods_zero_inflation}</p>
<dl class="simple myst">
<dt>Zero-inflation</dt><dd><p>An excess of zeros that is “so large that those expected in standard distributions (e.g., normal, Poisson, binomial, negative binomial and beta)” (Heilbron, 1994) violate the assumptions of such distributions (Martin et al., 2005). Excess zeroes can be a result of ecological effects (“true” zeros) or due to sampling or observer error (“false zeros”) (Martin et al., 2005). Excess zeroes contribute to overdispersion, but they don’t necessarily account for all excess variability (Blasco-Moreno et al., 2019).</p>
</dd>
</dl>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_dialog-boxes\09_gloss_ref"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../03_03_mod_occupancy.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Occupancy</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alberta Remote Camera Steering Committee (RCSC)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>